{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dataset = ImageFolder('Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = []\n",
    "\n",
    "def rename(name):\n",
    "    return ' '.join(' '.join(name.split('-')[1:]).split('_'))\n",
    "\n",
    "for n in dataset.classes:\n",
    "    breeds.append(rename(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training, validation and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 45\n",
    "torch.manual_seed(random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pct = 0.3\n",
    "test_size = int(len(dataset)*test_pct)\n",
    "dataset_size = len(dataset) - test_size\n",
    "\n",
    "val_pct = 0.1\n",
    "val_size = int(dataset_size*val_pct)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "\n",
    "train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_ds[6]\n",
    "print(dataset.classes[label])\n",
    "plt.imshow(img)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our custom Dataset, we need to extend Pytorch's `Dataset` class.\n",
    "We need to implement 3 methods inside our Custom Dataset Class:\n",
    "\n",
    "1. `__init__`\n",
    "2. `__len__`\n",
    "3. `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ds, transform=None):\n",
    "        self.ds = ds\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.ds[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)  \n",
    "            return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "#    transforms.Resize((224, 224)),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224, padding=4, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ToTensor(),\n",
    "#    transforms.Normalize(*imagenet_stats, inplace=True)\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "#    transforms.Normalize(*imagenet_stats, inplace=True)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)), \n",
    "    transforms.ToTensor(),\n",
    "#    transforms.Normalize(*imagenet_stats, inplace=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogBreedDataset(train_ds, train_transform)\n",
    "val_dataset = DogBreedDataset(val_ds, val_transform)\n",
    "test_dataset = DogBreedDataset(test_ds, test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets quickly take a look into our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[6]\n",
    "print(label)\n",
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create Training , validation data and test data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =64\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dl = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers=2, pin_memory=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size*2, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a peek into our dataset by creating grid of images using Pytorch's `make_grid()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for img, lb in dl:\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(img.cpu(), nrow=16).permute(1,2,0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    # training step\n",
    "    def training_step(self, batch):\n",
    "        img, targets = batch\n",
    "        out = self(img)\n",
    "        loss = F.nll_loss(out, targets)\n",
    "        return loss\n",
    "    \n",
    "    # validation step\n",
    "    def validation_step(self, batch):\n",
    "        img, targets = batch\n",
    "        out = self(img)\n",
    "        loss = F.nll_loss(out, targets)\n",
    "        acc = accuracy(out, targets)\n",
    "        return {'val_acc':acc.detach(), 'val_loss':loss.detach()}\n",
    "    \n",
    "    # validation epoch end\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return {'val_loss':epoch_loss.item(), 'val_acc':epoch_acc.item()}\n",
    "        \n",
    "    # print result end epoch\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}] : train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedClassificationCNN(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=1, padding=1),   # 224 * 244 * 32\n",
    "            nn.ReLU(),                                   \n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1),       \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                         # 112 * 112 * 32\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),   # 112 * 112* 64\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),    # 112 * 112* 128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),                          # 56 * 56* 128\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1),   # 56*56*256\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),  # 56*56*256\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2,2),                        # 28*28*256\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),                            # 14*14*256\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),                            # 7*7*256\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 120),\n",
    "            nn.LogSoftmax(dim = 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DogBreedClassificationCNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define ResNet-34 Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedResnet34(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.resnet34(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 120),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DogBreedPretrainedResnet34()\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now use some more pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedInceptionV3(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.inception_v3(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 120),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = DogBreedPretrainedInceptionV3()\n",
    "# model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedResnet152(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.resnet152(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 120),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = DogBreedPretrainedResnet152()\n",
    "model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedVGG16(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.vgg16(pretrained=True)\n",
    "        # Replace last layer  \n",
    "        self.network.classifier = nn.Sequential(\n",
    "           nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "           nn.ReLU(inplace=True),\n",
    "           nn.Dropout(p=0.5, inplace=False),\n",
    "           nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "           nn.ReLU(inplace=True),\n",
    "           nn.Dropout(p=0.5, inplace=False),\n",
    "           nn.Linear(in_features=4096, out_features=120, bias=True),\n",
    "           nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = DogBreedPretrainedVGG16()\n",
    "model5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedGoogleNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.googlenet(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 120),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = DogBreedPretrainedGoogleNet()\n",
    "model6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedDenseNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.densenet161(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.classifier.in_features\n",
    "        self.network.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 120),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = DogBreedPretrainedDenseNet()\n",
    "model7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide ResNet-50-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedPretrainedWideResnet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = models.wide_resnet50_2(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 120),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DogBreedPretrainedWideResnet()\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(d, device) for d in data]\n",
    "    else:\n",
    "        return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader:\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield to_device(batch, self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting default device\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "# moving train dataloader and val dataloader to gpu\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "\n",
    "\n",
    "# moving model to gpu\n",
    "to_device(model, device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model \n",
    "def try_batch(dl):\n",
    "    for imgs, labels in dl:\n",
    "        print(\"images shape : \", imgs.shape)\n",
    "        print(\"labels : \", labels)\n",
    "        outs = model1(imgs)                                  # Change model object here\n",
    "        print(\"outs.shape :\", outs.shape)\n",
    "        print(\"outs : \", outs)\n",
    "        break\n",
    "        \n",
    "try_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "        \n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func = torch.optim.Adam):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # set up one cycle lr scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()       \n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            \n",
    "            # calculates gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # check gradient clipping \n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "                \n",
    "            # perform gradient descent and modifies the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # reset the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # record and update lr\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            \n",
    "            # modifies the lr value\n",
    "            sched.step()\n",
    "            \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "        \n",
    "    return history\n",
    "        \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model1, val_dl)                 # change model object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparams\n",
    "num_epochs = 5\n",
    "opt_func = torch.optim.SGD\n",
    "\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit_one_cycle(num_epochs, max_lr, model1, train_dl, val_dl, weight_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "max_lr = 0.001\n",
    "history += fit_one_cycle(num_epochs, max_lr, model1, train_dl, val_dl, weight_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "max_lr = 0.0001\n",
    "history += fit_one_cycle(num_epochs, max_lr, model1, train_dl, val_dl, weight_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "time = list(range(len(history)))\n",
    "for h in history:\n",
    "    val_loss.append(h['val_loss'])\n",
    "    train_loss.append(h['train_loss'])\n",
    "    val_acc.append(h['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss v/s Epochs plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, val_loss, c='red', label='val_loss', marker='x')\n",
    "plt.plot(time, train_loss, c='blue', label='train_loss', marker='x')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy v/s Epochs plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, val_acc, c='red', label='accuracy', marker='x')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('lr')\n",
    "plt.plot(lrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(img, label):\n",
    "    xb = img.unsqueeze(0) # adding extra dimension\n",
    "    xb = to_device(xb, device)\n",
    "    preds = model1(xb)                   # change model object here\n",
    "    predictions = preds[0]\n",
    "    \n",
    "    max_val, kls = torch.max(predictions, dim=0)\n",
    "    print('Actual :', breeds[label], ' | Predicted :', breeds[kls])\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single(*test_dataset[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single(*test_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single(*test_dataset[93])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(model1, test_dl)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_fname = 'dog-breed-classifier-wideresnet_with_data_aug.pth'\n",
    "torch.save(model4.state_dict(), weights_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit to Jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.reset()\n",
    "jovian.log_hyperparams(arch='wideresnet_with_data_aug', \n",
    "                       epochs=len(history), \n",
    "                       max_lr_01=0.01,\n",
    "                       max_lr_02=0.001,\n",
    "                       max_lr_03=0.0001,\n",
    "                       scheduler='one-cycle', \n",
    "                       batch_size = batch_size,\n",
    "                       weight_decay=weight_decay, \n",
    "                       grad_clip=grad_clip,\n",
    "                       opt=opt_func.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.log_metrics(\n",
    "    train_loss=history[-1]['train_loss'],\n",
    "    val_loss=history[-1]['val_loss'], \n",
    "    val_score=history[-1]['val_acc'],\n",
    "    test_score=result['val_acc'],\n",
    "    test_loss=result['val_loss']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='dog-breed-classifier-final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project=project_name, environment=None, outputs=[weights_fname])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
